{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shreenidhihegde/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shreenidhihegde/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreenidhihegde/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 16148: expected 15 fields, saw 22\\nSkipping line 20100: expected 15 fields, saw 22\\nSkipping line 45178: expected 15 fields, saw 22\\nSkipping line 48700: expected 15 fields, saw 22\\nSkipping line 63331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 86053: expected 15 fields, saw 22\\nSkipping line 88858: expected 15 fields, saw 22\\nSkipping line 115017: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 137366: expected 15 fields, saw 22\\nSkipping line 139110: expected 15 fields, saw 22\\nSkipping line 165540: expected 15 fields, saw 22\\nSkipping line 171813: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 203723: expected 15 fields, saw 22\\nSkipping line 209366: expected 15 fields, saw 22\\nSkipping line 211310: expected 15 fields, saw 22\\nSkipping line 246351: expected 15 fields, saw 22\\nSkipping line 252364: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 267003: expected 15 fields, saw 22\\nSkipping line 268957: expected 15 fields, saw 22\\nSkipping line 303336: expected 15 fields, saw 22\\nSkipping line 306021: expected 15 fields, saw 22\\nSkipping line 311569: expected 15 fields, saw 22\\nSkipping line 316767: expected 15 fields, saw 22\\nSkipping line 324009: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 359107: expected 15 fields, saw 22\\nSkipping line 368367: expected 15 fields, saw 22\\nSkipping line 381180: expected 15 fields, saw 22\\nSkipping line 390453: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 412243: expected 15 fields, saw 22\\nSkipping line 419342: expected 15 fields, saw 22\\nSkipping line 457388: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 459935: expected 15 fields, saw 22\\nSkipping line 460167: expected 15 fields, saw 22\\nSkipping line 466460: expected 15 fields, saw 22\\nSkipping line 500314: expected 15 fields, saw 22\\nSkipping line 500339: expected 15 fields, saw 22\\nSkipping line 505396: expected 15 fields, saw 22\\nSkipping line 507760: expected 15 fields, saw 22\\nSkipping line 513626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 527638: expected 15 fields, saw 22\\nSkipping line 534209: expected 15 fields, saw 22\\nSkipping line 535687: expected 15 fields, saw 22\\nSkipping line 547671: expected 15 fields, saw 22\\nSkipping line 549054: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 599929: expected 15 fields, saw 22\\nSkipping line 604776: expected 15 fields, saw 22\\nSkipping line 609937: expected 15 fields, saw 22\\nSkipping line 632059: expected 15 fields, saw 22\\nSkipping line 638546: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 665017: expected 15 fields, saw 22\\nSkipping line 677680: expected 15 fields, saw 22\\nSkipping line 684370: expected 15 fields, saw 22\\nSkipping line 720217: expected 15 fields, saw 29\\n'\n",
      "b'Skipping line 723240: expected 15 fields, saw 22\\nSkipping line 723433: expected 15 fields, saw 22\\nSkipping line 763891: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 800288: expected 15 fields, saw 22\\nSkipping line 802942: expected 15 fields, saw 22\\nSkipping line 803379: expected 15 fields, saw 22\\nSkipping line 805122: expected 15 fields, saw 22\\nSkipping line 821899: expected 15 fields, saw 22\\nSkipping line 831707: expected 15 fields, saw 22\\nSkipping line 842829: expected 15 fields, saw 22\\nSkipping line 843604: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 863904: expected 15 fields, saw 22\\nSkipping line 875655: expected 15 fields, saw 22\\nSkipping line 886796: expected 15 fields, saw 22\\nSkipping line 892299: expected 15 fields, saw 22\\nSkipping line 902518: expected 15 fields, saw 22\\nSkipping line 903079: expected 15 fields, saw 22\\nSkipping line 912678: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 932953: expected 15 fields, saw 22\\nSkipping line 936838: expected 15 fields, saw 22\\nSkipping line 937177: expected 15 fields, saw 22\\nSkipping line 947695: expected 15 fields, saw 22\\nSkipping line 960713: expected 15 fields, saw 22\\nSkipping line 965225: expected 15 fields, saw 22\\nSkipping line 980776: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 999318: expected 15 fields, saw 22\\nSkipping line 1007247: expected 15 fields, saw 22\\nSkipping line 1015987: expected 15 fields, saw 22\\nSkipping line 1018984: expected 15 fields, saw 22\\nSkipping line 1028671: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1063360: expected 15 fields, saw 22\\nSkipping line 1066195: expected 15 fields, saw 22\\nSkipping line 1066578: expected 15 fields, saw 22\\nSkipping line 1066869: expected 15 fields, saw 22\\nSkipping line 1068809: expected 15 fields, saw 22\\nSkipping line 1069505: expected 15 fields, saw 22\\nSkipping line 1087983: expected 15 fields, saw 22\\nSkipping line 1108184: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1118137: expected 15 fields, saw 22\\nSkipping line 1142723: expected 15 fields, saw 22\\nSkipping line 1152492: expected 15 fields, saw 22\\nSkipping line 1156947: expected 15 fields, saw 22\\nSkipping line 1172563: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1209254: expected 15 fields, saw 22\\nSkipping line 1212966: expected 15 fields, saw 22\\nSkipping line 1236533: expected 15 fields, saw 22\\nSkipping line 1237598: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1273825: expected 15 fields, saw 22\\nSkipping line 1277898: expected 15 fields, saw 22\\nSkipping line 1283654: expected 15 fields, saw 22\\nSkipping line 1286023: expected 15 fields, saw 22\\nSkipping line 1302038: expected 15 fields, saw 22\\nSkipping line 1305179: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1326022: expected 15 fields, saw 22\\nSkipping line 1338120: expected 15 fields, saw 22\\nSkipping line 1338503: expected 15 fields, saw 22\\nSkipping line 1338849: expected 15 fields, saw 22\\nSkipping line 1341513: expected 15 fields, saw 22\\nSkipping line 1346493: expected 15 fields, saw 22\\nSkipping line 1373127: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1389508: expected 15 fields, saw 22\\nSkipping line 1413951: expected 15 fields, saw 22\\nSkipping line 1433626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1442698: expected 15 fields, saw 22\\nSkipping line 1472982: expected 15 fields, saw 22\\nSkipping line 1482282: expected 15 fields, saw 22\\nSkipping line 1487808: expected 15 fields, saw 22\\nSkipping line 1500636: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1511479: expected 15 fields, saw 22\\nSkipping line 1532302: expected 15 fields, saw 22\\nSkipping line 1537952: expected 15 fields, saw 22\\nSkipping line 1539951: expected 15 fields, saw 22\\nSkipping line 1541020: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1594217: expected 15 fields, saw 22\\nSkipping line 1612264: expected 15 fields, saw 22\\nSkipping line 1615907: expected 15 fields, saw 22\\nSkipping line 1621859: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1653542: expected 15 fields, saw 22\\nSkipping line 1671537: expected 15 fields, saw 22\\nSkipping line 1672879: expected 15 fields, saw 22\\nSkipping line 1674523: expected 15 fields, saw 22\\nSkipping line 1677355: expected 15 fields, saw 22\\nSkipping line 1703907: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1713046: expected 15 fields, saw 22\\nSkipping line 1722982: expected 15 fields, saw 22\\nSkipping line 1727290: expected 15 fields, saw 22\\nSkipping line 1744482: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1803858: expected 15 fields, saw 22\\nSkipping line 1810069: expected 15 fields, saw 22\\nSkipping line 1829751: expected 15 fields, saw 22\\nSkipping line 1831699: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1863131: expected 15 fields, saw 22\\nSkipping line 1867917: expected 15 fields, saw 22\\nSkipping line 1874790: expected 15 fields, saw 22\\nSkipping line 1879952: expected 15 fields, saw 22\\nSkipping line 1880501: expected 15 fields, saw 22\\nSkipping line 1886655: expected 15 fields, saw 22\\nSkipping line 1887888: expected 15 fields, saw 22\\nSkipping line 1894286: expected 15 fields, saw 22\\nSkipping line 1895400: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1904040: expected 15 fields, saw 22\\nSkipping line 1907604: expected 15 fields, saw 22\\nSkipping line 1915739: expected 15 fields, saw 22\\nSkipping line 1921514: expected 15 fields, saw 22\\nSkipping line 1939428: expected 15 fields, saw 22\\nSkipping line 1944342: expected 15 fields, saw 22\\nSkipping line 1949699: expected 15 fields, saw 22\\nSkipping line 1961872: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1968846: expected 15 fields, saw 22\\nSkipping line 1999941: expected 15 fields, saw 22\\nSkipping line 2001492: expected 15 fields, saw 22\\nSkipping line 2011204: expected 15 fields, saw 22\\nSkipping line 2025295: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2041266: expected 15 fields, saw 22\\nSkipping line 2073314: expected 15 fields, saw 22\\nSkipping line 2080133: expected 15 fields, saw 22\\nSkipping line 2088521: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2103490: expected 15 fields, saw 22\\nSkipping line 2115278: expected 15 fields, saw 22\\nSkipping line 2153174: expected 15 fields, saw 22\\nSkipping line 2161731: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2165250: expected 15 fields, saw 22\\nSkipping line 2175132: expected 15 fields, saw 22\\nSkipping line 2206817: expected 15 fields, saw 22\\nSkipping line 2215848: expected 15 fields, saw 22\\nSkipping line 2223811: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2257265: expected 15 fields, saw 22\\nSkipping line 2259163: expected 15 fields, saw 22\\nSkipping line 2263291: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2301943: expected 15 fields, saw 22\\nSkipping line 2304371: expected 15 fields, saw 22\\nSkipping line 2306015: expected 15 fields, saw 22\\nSkipping line 2312186: expected 15 fields, saw 22\\nSkipping line 2314740: expected 15 fields, saw 22\\nSkipping line 2317754: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2383514: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2449763: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2589323: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2775036: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2935174: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3078830: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3123091: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3185533: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4150395: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4748401: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    " \"\"\"\n",
    " Here we are reading the data from tsv file as pandas dataframe.\n",
    " We use '\\t' to seperate columns by a tab and \"error_bad_lines = False\" to drop bad lines from the DataFrame\n",
    " \n",
    " \"\"\"  \n",
    "text_data = pd.read_csv(\"data.tsv\",error_bad_lines = False, sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Three sample reviews with corresponding ratings -x--x- \n",
      "\n",
      "         star_rating                                        review_body\n",
      "2264076          5.0  Do you know what's better than a Seattle Seaha...\n",
      "2973343          4.0  the soup bowls are little bit smaller for nood...\n",
      "2090625          3.0   They stain easy & handles get really hot to grab\n",
      "\n",
      " -x--x- Statistics of the ratings -x--x- \n",
      "\n",
      "5.0    3124595\n",
      "4.0     731701\n",
      "1.0     426870\n",
      "3.0     349539\n",
      "2.0     241939\n",
      "Name: star_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    #We are using dropna to look for missing values in the rows which has no review body and drop the corresponding rows.\n",
    "    \n",
    "    text_data.dropna(subset = ['review_body'], inplace= True)\n",
    "    text_data.dropna(subset = ['star_rating'], inplace= True)\n",
    "    \n",
    "    \n",
    "    # We Keep only the reviews and ratings of the initial data\n",
    "    text_data = text_data[[\"star_rating\",\"review_body\"]]\n",
    "    \n",
    "    # We are including 3 sample reviews with the corresponding rating\n",
    "    print (\"\\n -x--x- Three sample reviews with corresponding ratings -x--x- \\n\")\n",
    "    print (text_data.sample(n=3, random_state=100))\n",
    "    \n",
    "    # We are reporting statistics of the ratings\n",
    "    star_counts = text_data[\"star_rating\"].value_counts()\n",
    "    print(\"\\n -x--x- Statistics of the ratings -x--x- \\n\")\n",
    "    print(star_counts)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling Reviews:\n",
    "## The reviews with rating 4,5 are labelled to be 1 and 1,2 are labelled as 0. Discard the reviews with rating 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Counts of all review labels before removing the reviews with rating 3 -x--x-\n",
      "\n",
      " 1    3856296\n",
      " 0     668809\n",
      "-1     349539\n",
      "Name: label, dtype: int64\n",
      "\n",
      " -x--x- Counts of all review labels after removing the reviews with rating 3 -x--x- \n",
      "\n",
      "1    3856296\n",
      "0     668809\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using np.where we are putting conditions to label the ratings >=4 as 1 and ratins <=2 as 0. \n",
    "#The remainign ratings which is labelled as 3 will be labelled as -1.\n",
    "\n",
    "text_data['label'] = np.where(text_data[\"star_rating\"] >=4,1, np.where(text_data[\"star_rating\"] <= 2,0,-1))\n",
    "rating_count = text_data['label'].value_counts()\n",
    "\n",
    "#We are getting the counts of all review labels before removing the reviews with rating 3\n",
    "print(\"\\n -x--x- Counts of all review labels before removing the reviews with rating 3 -x--x-\\n\")\n",
    "print(rating_count)\n",
    "\n",
    "#Discarding the reviews with rating 3\n",
    "text_data = text_data[text_data[\"label\"]!= -1]\n",
    "\n",
    "#We are getting the counts of all review labels after removing the reviews with rating 3\n",
    "print(\"\\n -x--x- Counts of all review labels after removing the reviews with rating 3 -x--x- \\n\")\n",
    "print(text_data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We select 200000 reviews randomly with 100,000 positive and 100,000 negative reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- The average length of the reviews in terms of character length in the dataset before cleaning is -x--x- \n",
      "323.45\n",
      "\n",
      " -x--x- The sample reviews before cleaning -x--x- \n",
      "\n",
      "4471705    I ordered this Coffee Maker Nov 2009 and it wa...\n",
      "231497     Cracked plastic base and is not airtight aroun...\n",
      "1986586    This item was received with scratches all over...\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#We select sample of 100,000 positive and 100,000 negative reviews\n",
    "negative = text_data.label[text_data.label.eq(0)].sample(100000).index\n",
    "positive = text_data.label[text_data.label.eq(1)].sample(100000).index\n",
    "\n",
    "#We combine both the selected samples\n",
    "text_data = text_data.loc[negative.union(positive)]\n",
    "\n",
    "# We are getting mean of each row based on characters in each row and then finding the mean of all the rows\n",
    "review_mean = text_data.review_body.apply(lambda x : len(str(x))).mean()\n",
    "# print 3 sample reviews\n",
    "\n",
    "print(f'\\n -x--x- The average length of the reviews in terms of character length in the dataset before cleaning is -x--x- \\n{review_mean:.2f}')\n",
    "print(\"\\n -x--x- The sample reviews before cleaning -x--x- \\n\")\n",
    "print(text_data[\"review_body\"].sample(n=3, random_state=100))\n",
    "\n",
    "\n",
    "                                          \n",
    "                                                                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Convert the all reviews into the lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use str.lower() to convert all the characters into lower characters\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreenidhihegde/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/bs4/__init__.py:417: MarkupResemblesLocatorWarning: \"https://www.amazon.com/gp/profile/a3fci1qhe8fngz\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#We use Beatiful soup to remove all the HTML Tags from the dataframe\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: BeautifulSoup(str(x),\"html.parser\").get_text())\n",
    "\n",
    "# We are here removing the URLs from the reviews\n",
    "Url_pattern = r'\\s*(https?://|www\\.)+\\S+(\\s+|$)'\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(Url_pattern, \" \", str(x), flags=re.UNICODE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we remove all the words starts with digits\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(r\"[^\\D']+\", \" \", str(x), flags=re.UNICODE))\n",
    "\n",
    "#Next we remove all the words which starts with non alphabetic characters\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(r\"[^\\w']+\", \" \", str(x), flags=re.UNICODE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the extra spaces between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the extra spaces from the dataset\n",
    "# text_data[\"review_body\"] = text_data[\"review_body\"].replace('\\s+', ' ', regex=True)\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x), flags=re.UNICODE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform contractions on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We perform contractions using contractions.fix\n",
    "\n",
    "def contractionfunction(i):\n",
    "    i = i.apply(lambda x: contractions.fix(x))\n",
    "    return i\n",
    "\n",
    "text_data[\"review_body\"] = contractionfunction(text_data[\"review_body\"])\n",
    "#We convert the characters into lowercase again as after contractions some words will get capitalized Ex: \"i'm will\" become \"I am\" after contraction.\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- The average length of the reviews in terms of character length in the dataset after cleaning is -x--x-\n",
      " 310.22597\n",
      "\n",
      " -x--x- The sample reviews after cleaning -x--x-\n",
      "\n",
      "4471705    i ordered this coffee maker nov and it was fin...\n",
      "231497     cracked plastic base and is not airtight aroun...\n",
      "1986586    this item was received with scratches all over...\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "review_mean_new = text_data.review_body.apply(lambda x :len(str(x))).mean()\n",
    "print(\"\\n -x--x- The average length of the reviews in terms of character length in the dataset after cleaning is -x--x-\\n\", review_mean_new)\n",
    "print(\"\\n -x--x- The sample reviews after cleaning -x--x-\\n\")\n",
    "print(text_data[\"review_body\"].sample(n=3, random_state=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are removing stop words \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: \" \".join([i for i in x.split() if i not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We perform lemmatization on the data\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: \" \".join(lemmatizer.lemmatize(i) for i in x.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- The average length of the reviews in terms of character length in the dataset after pre-processing is -x--x- \n",
      " 189.801875\n",
      "\n",
      " -x--x- The sample reviews after pre-processing -x--x-\n",
      "\n",
      "4471705    ordered coffee maker nov finally delivered mar...\n",
      "231497     cracked plastic base airtight around lid poor ...\n",
      "1986586      item received scratch used already disappointed\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "review_mean_3 = text_data.review_body.apply(lambda x : np.mean(len(str(x)))).mean()\n",
    "print(\"\\n -x--x- The average length of the reviews in terms of character length in the dataset after pre-processing is -x--x- \\n\", review_mean_3)\n",
    "print(\"\\n -x--x- The sample reviews after pre-processing -x--x-\\n\")\n",
    "print(text_data[\"review_body\"].sample(n=3, random_state=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use train_test_split from sklearn to split the data into 80% training and 20% testing sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data[\"review_body\"], text_data[\"label\"], test_size=0.2, random_state=100)\n",
    "\n",
    "#We ignore terms that have a document frequency strictly higher 0.7 and document frequency strictly lower than 1.\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_df=0.7)\n",
    "Xtrain = vectorizer.fit_transform(X_train)\n",
    "Xtest = vectorizer.transform(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize the data using StandardScaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create the instance\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "#We fit the scaler to the training feauture set only\n",
    "sc.fit(Xtrain)\n",
    "\n",
    "#Scale or Transform the training and the testing tests using the scaler that was fitted to training data\n",
    "Xtrain_std = sc.transform(Xtrain)\n",
    "Xtest_std = sc.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x-\n",
      "\n",
      "Testing Accuracy:0.8267\n",
      "Testing f1_Score:0.8275\n",
      "Testing Precision:0.8204\n",
      "Testing recall_score:0.8346\n",
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\n",
      "\n",
      "Training Accuracy:0.9264\n",
      "Training f1_Score:0.9268\n",
      "Training Precision:0.9234\n",
      "Training recall_score:0.9302\n"
     ]
    }
   ],
   "source": [
    "#implementation of perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Create a perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1\n",
    "ppn = Perceptron(max_iter=40, eta0=0.1, random_state=100)\n",
    "\n",
    "# Fit the model to the standardized data\n",
    "ppn.fit(Xtrain_std, y_train)\n",
    "\n",
    "\n",
    "# Apply the trained perceptron on the X data to make predicts for the Y test data\n",
    "y_pred_test = ppn.predict(Xtest_std)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_score,precision_score and recall_score\"\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x-\\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = ppn.predict(Xtrain_std)\n",
    "\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \n",
      "\n",
      "Testing Accuracy:0.8961\n",
      "Testing f1_Score:0.8958\n",
      "Testing Precision:0.8943\n",
      "Testing recall_score:0.8973\n",
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \n",
      "\n",
      "Training Accuracy:0.9338\n",
      "Training f1_Score:0.9338\n",
      "Training Precision:0.9349\n",
      "Training recall_score:0.9327\n"
     ]
    }
   ],
   "source": [
    "#implementation of SVM\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a Classifier for svm\n",
    "clf = svm.LinearSVC() # We are using Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(Xtrain, y_train)\n",
    "\n",
    "#Apply the trained svm on Xtrain_std data to make predictions for the test data\n",
    "y_pred_test = clf.predict(Xtest)\n",
    "\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = clf.predict(Xtrain)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_Score,Precision_score and recall_score\"\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-x--x- Accuracy, Precision, Recall, and f1-score on test data --x--x-\n",
      "\n",
      "Testing Accuracy:0.9001\n",
      "Testing f1_Score:0.8993\n",
      "Testing Precision:0.9025\n",
      "Testing recall_score:0.8960\n",
      "\n",
      "-x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\n",
      "\n",
      "Training Accuracy:0.9143\n",
      "Training f1_Score:0.9141\n",
      "Training Precision:0.9171\n",
      "Training recall_score:0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreenidhihegde/opt/anaconda3/envs/NLP/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiate the model \n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(Xtrain,y_train)\n",
    "\n",
    "#Apply the trained Logistic Regression on Xtrain_std data to make predictions for the test data\n",
    "y_pred_test=logreg.predict(Xtest)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_Score,Precision_score and recall_score\"\n",
    "print(\"\\n-x--x- Accuracy, Precision, Recall, and f1-score on test data --x--x-\\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = logreg.predict(Xtrain)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score\"\n",
    "\n",
    "print(\"\\n-x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \n",
      "\n",
      "Testing Accuracy:0.8713\n",
      "Testing f1_Score:0.8703\n",
      "Testing Precision:0.8734\n",
      "Testing recall_score:0.8671\n",
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \n",
      "\n",
      "Training Accuracy:0.8869\n",
      "Training f1_Score:0.8867\n",
      "Training Precision:0.8894\n",
      "Training recall_score:0.8840\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(Xtrain, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred_test=model.predict(Xtest)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_Score,Precision_score and recall_score\"\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = model.predict(Xtrain)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score\"\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
