{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shreenidhihegde/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shreenidhihegde/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 16148: expected 15 fields, saw 22\\nSkipping line 20100: expected 15 fields, saw 22\\nSkipping line 45178: expected 15 fields, saw 22\\nSkipping line 48700: expected 15 fields, saw 22\\nSkipping line 63331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 86053: expected 15 fields, saw 22\\nSkipping line 88858: expected 15 fields, saw 22\\nSkipping line 115017: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 137366: expected 15 fields, saw 22\\nSkipping line 139110: expected 15 fields, saw 22\\nSkipping line 165540: expected 15 fields, saw 22\\nSkipping line 171813: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 203723: expected 15 fields, saw 22\\nSkipping line 209366: expected 15 fields, saw 22\\nSkipping line 211310: expected 15 fields, saw 22\\nSkipping line 246351: expected 15 fields, saw 22\\nSkipping line 252364: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 267003: expected 15 fields, saw 22\\nSkipping line 268957: expected 15 fields, saw 22\\nSkipping line 303336: expected 15 fields, saw 22\\nSkipping line 306021: expected 15 fields, saw 22\\nSkipping line 311569: expected 15 fields, saw 22\\nSkipping line 316767: expected 15 fields, saw 22\\nSkipping line 324009: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 359107: expected 15 fields, saw 22\\nSkipping line 368367: expected 15 fields, saw 22\\nSkipping line 381180: expected 15 fields, saw 22\\nSkipping line 390453: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 412243: expected 15 fields, saw 22\\nSkipping line 419342: expected 15 fields, saw 22\\nSkipping line 457388: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 459935: expected 15 fields, saw 22\\nSkipping line 460167: expected 15 fields, saw 22\\nSkipping line 466460: expected 15 fields, saw 22\\nSkipping line 500314: expected 15 fields, saw 22\\nSkipping line 500339: expected 15 fields, saw 22\\nSkipping line 505396: expected 15 fields, saw 22\\nSkipping line 507760: expected 15 fields, saw 22\\nSkipping line 513626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 527638: expected 15 fields, saw 22\\nSkipping line 534209: expected 15 fields, saw 22\\nSkipping line 535687: expected 15 fields, saw 22\\nSkipping line 547671: expected 15 fields, saw 22\\nSkipping line 549054: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 599929: expected 15 fields, saw 22\\nSkipping line 604776: expected 15 fields, saw 22\\nSkipping line 609937: expected 15 fields, saw 22\\nSkipping line 632059: expected 15 fields, saw 22\\nSkipping line 638546: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 665017: expected 15 fields, saw 22\\nSkipping line 677680: expected 15 fields, saw 22\\nSkipping line 684370: expected 15 fields, saw 22\\nSkipping line 720217: expected 15 fields, saw 29\\n'\n",
      "b'Skipping line 723240: expected 15 fields, saw 22\\nSkipping line 723433: expected 15 fields, saw 22\\nSkipping line 763891: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 800288: expected 15 fields, saw 22\\nSkipping line 802942: expected 15 fields, saw 22\\nSkipping line 803379: expected 15 fields, saw 22\\nSkipping line 805122: expected 15 fields, saw 22\\nSkipping line 821899: expected 15 fields, saw 22\\nSkipping line 831707: expected 15 fields, saw 22\\nSkipping line 842829: expected 15 fields, saw 22\\nSkipping line 843604: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 863904: expected 15 fields, saw 22\\nSkipping line 875655: expected 15 fields, saw 22\\nSkipping line 886796: expected 15 fields, saw 22\\nSkipping line 892299: expected 15 fields, saw 22\\nSkipping line 902518: expected 15 fields, saw 22\\nSkipping line 903079: expected 15 fields, saw 22\\nSkipping line 912678: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 932953: expected 15 fields, saw 22\\nSkipping line 936838: expected 15 fields, saw 22\\nSkipping line 937177: expected 15 fields, saw 22\\nSkipping line 947695: expected 15 fields, saw 22\\nSkipping line 960713: expected 15 fields, saw 22\\nSkipping line 965225: expected 15 fields, saw 22\\nSkipping line 980776: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 999318: expected 15 fields, saw 22\\nSkipping line 1007247: expected 15 fields, saw 22\\nSkipping line 1015987: expected 15 fields, saw 22\\nSkipping line 1018984: expected 15 fields, saw 22\\nSkipping line 1028671: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1063360: expected 15 fields, saw 22\\nSkipping line 1066195: expected 15 fields, saw 22\\nSkipping line 1066578: expected 15 fields, saw 22\\nSkipping line 1066869: expected 15 fields, saw 22\\nSkipping line 1068809: expected 15 fields, saw 22\\nSkipping line 1069505: expected 15 fields, saw 22\\nSkipping line 1087983: expected 15 fields, saw 22\\nSkipping line 1108184: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1118137: expected 15 fields, saw 22\\nSkipping line 1142723: expected 15 fields, saw 22\\nSkipping line 1152492: expected 15 fields, saw 22\\nSkipping line 1156947: expected 15 fields, saw 22\\nSkipping line 1172563: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1209254: expected 15 fields, saw 22\\nSkipping line 1212966: expected 15 fields, saw 22\\nSkipping line 1236533: expected 15 fields, saw 22\\nSkipping line 1237598: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    " \"\"\"\n",
    " Here we are reading the data from tsv file as pandas dataframe.\n",
    " We use '\\t' to seperate columns by a tab and \"error_bad_lines = False\" to drop bad lines from the DataFrame\n",
    " \n",
    " \"\"\"  \n",
    "text_data = pd.read_csv(\"data.tsv\",error_bad_lines = False, sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Three sample reviews with corresponding ratings -x--x- \n",
      "\n",
      "         star_rating                                        review_body\n",
      "2264076          5.0  Do you know what's better than a Seattle Seaha...\n",
      "2973343          4.0  the soup bowls are little bit smaller for nood...\n",
      "2090625          3.0   They stain easy & handles get really hot to grab\n",
      "\n",
      " -x--x- Statistics of the ratings -x--x- \n",
      "\n",
      "5.0    3124595\n",
      "4.0     731701\n",
      "1.0     426870\n",
      "3.0     349539\n",
      "2.0     241939\n",
      "Name: star_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    #We are using dropna to look for missing values in the rows which has no review body and drop the corresponding rows.\n",
    "    \n",
    "    text_data.dropna(subset = ['review_body'], inplace= True)\n",
    "    text_data.dropna(subset = ['star_rating'], inplace= True)\n",
    "    \n",
    "    \n",
    "    # We Keep only the reviews and ratings of the initial data\n",
    "    text_data = text_data[[\"star_rating\",\"review_body\"]]\n",
    "    \n",
    "    # We are including 3 sample reviews with the corresponding rating\n",
    "    print (\"\\n -x--x- Three sample reviews with corresponding ratings -x--x- \\n\")\n",
    "    print (text_data.sample(n=3, random_state=100))\n",
    "    \n",
    "    # We are reporting statistics of the ratings\n",
    "    star_counts = text_data[\"star_rating\"].value_counts()\n",
    "    print(\"\\n -x--x- Statistics of the ratings -x--x- \\n\")\n",
    "    print(star_counts)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling Reviews:\n",
    "## The reviews with rating 4,5 are labelled to be 1 and 1,2 are labelled as 0. Discard the reviews with rating 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Counts of all review labels before removing the reviews with rating 3 -x--x-\n",
      "\n",
      " 1    3856296\n",
      " 0     668809\n",
      "-1     349539\n",
      "Name: label, dtype: int64\n",
      "\n",
      " -x--x- Counts of all review labels after removing the reviews with rating 3 -x--x- \n",
      "\n",
      "1    3856296\n",
      "0     668809\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using np.where we are putting conditions to label the ratings >=4 as 1 and ratins <=2 as 0. \n",
    "#The remainign ratings which is labelled as 3 will be labelled as -1.\n",
    "\n",
    "text_data['label'] = np.where(text_data[\"star_rating\"] >=4,1, np.where(text_data[\"star_rating\"] <= 2,0,-1))\n",
    "rating_count = text_data['label'].value_counts()\n",
    "\n",
    "#We are getting the counts of all review labels before removing the reviews with rating 3\n",
    "print(\"\\n -x--x- Counts of all review labels before removing the reviews with rating 3 -x--x-\\n\")\n",
    "print(rating_count)\n",
    "\n",
    "#Discarding the reviews with rating 3\n",
    "text_data = text_data[text_data[\"label\"]!= -1]\n",
    "\n",
    "#We are getting the counts of all review labels after removing the reviews with rating 3\n",
    "print(\"\\n -x--x- Counts of all review labels after removing the reviews with rating 3 -x--x- \\n\")\n",
    "print(text_data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We select 200000 reviews randomly with 100,000 positive and 100,000 negative reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- The average length of the reviews in terms of character length in the dataset before cleaning is -x--x- \n",
      "322.12\n",
      "\n",
      " -x--x- The sample reviews before cleaning -x--x- \n",
      "\n",
      "4471643    Ordered these in order to help organize my swe...\n",
      "227922     Expensive plastic ware. If they had been porce...\n",
      "1984131    they were not gold at all... they were actuall...\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#We select sample of 100,000 positive and 100,000 negative reviews\n",
    "negative = text_data.label[text_data.label.eq(0)].sample(100000).index\n",
    "positive = text_data.label[text_data.label.eq(1)].sample(100000).index\n",
    "\n",
    "#We combine both the selected samples\n",
    "text_data = text_data.loc[negative.union(positive)]\n",
    "\n",
    "# We are getting mean of each row based on characters in each row and then finding the mean of all the rows\n",
    "review_mean = text_data.review_body.apply(lambda x : len(str(x))).mean()\n",
    "# print 3 sample reviews\n",
    "\n",
    "print(f'\\n -x--x- The average length of the reviews in terms of character length in the dataset before cleaning is -x--x- \\n{review_mean:.2f}')\n",
    "print(\"\\n -x--x- The sample reviews before cleaning -x--x- \\n\")\n",
    "print(text_data[\"review_body\"].sample(n=3, random_state=100))\n",
    "\n",
    "\n",
    "                                          \n",
    "                                                                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Convert the all reviews into the lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use str.lower() to convert all the characters into lower characters\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use Beatiful soup to remove all the HTML Tags from the dataframe\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: BeautifulSoup(str(x),\"html.parser\").get_text())\n",
    "\n",
    "# We are here removing the URLs from the reviews\n",
    "Url_pattern = r'\\s*(https?://|www\\.)+\\S+(\\s+|$)'\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(Url_pattern, \" \", str(x), flags=re.UNICODE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we remove all the words starts with digits\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(r\"[^\\D']+\", \" \", str(x), flags=re.UNICODE))\n",
    "\n",
    "#Next we remove all the words which starts with non alphabetic characters\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(r\"[^\\w']+\", \" \", str(x), flags=re.UNICODE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the extra spaces between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We remove the extra spaces from the dataset\n",
    "# text_data[\"review_body\"] = text_data[\"review_body\"].replace('\\s+', ' ', regex=True)\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: re.sub(r\"\\s+\", \" \", str(x), flags=re.UNICODE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform contractions on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We perform contractions using contractions.fix\n",
    "\n",
    "def contractionfunction(i):\n",
    "    i = i.apply(lambda x: contractions.fix(x))\n",
    "    return i\n",
    "\n",
    "text_data[\"review_body\"] = contractionfunction(text_data[\"review_body\"])\n",
    "#We convert the characters into lowercase again as after contractions some words will get capitalized Ex: \"i'm will\" become \"I am\" after contraction.\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- The average length of the reviews in terms of character length in the dataset after cleaning is -x--x-\n",
      " 308.89177\n",
      "\n",
      " -x--x- The sample reviews after cleaning -x--x-\n",
      "\n",
      "4471643    ordered these in order to help organize my swe...\n",
      "227922     expensive plastic ware if they had been porcel...\n",
      "1984131    they were not gold at all they were actually b...\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "review_mean_new = text_data.review_body.apply(lambda x :len(str(x))).mean()\n",
    "print(\"\\n -x--x- The average length of the reviews in terms of character length in the dataset after cleaning is -x--x-\\n\", review_mean_new)\n",
    "print(\"\\n -x--x- The sample reviews after cleaning -x--x-\\n\")\n",
    "print(text_data[\"review_body\"].sample(n=3, random_state=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are removing stop words \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: \" \".join([i for i in x.split() if i not in stop_words]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We perform lemmatization on the data\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text_data[\"review_body\"] = text_data[\"review_body\"].apply(lambda x: \" \".join(lemmatizer.lemmatize(i) for i in x.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- The average length of the reviews in terms of character length in the dataset after pre-processing is -x--x- \n",
      " 188.983915\n",
      "\n",
      " -x--x- The sample reviews after pre-processing -x--x-\n",
      "\n",
      "4471643    ordered order help organize sweater shirt fold...\n",
      "227922                expensive plastic ware porcelain maybe\n",
      "1984131            gold actually brown color happy told gold\n",
      "Name: review_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "review_mean_3 = text_data.review_body.apply(lambda x : np.mean(len(str(x)))).mean()\n",
    "print(\"\\n -x--x- The average length of the reviews in terms of character length in the dataset after pre-processing is -x--x- \\n\", review_mean_3)\n",
    "print(\"\\n -x--x- The sample reviews after pre-processing -x--x-\\n\")\n",
    "print(text_data[\"review_body\"].sample(n=3, random_state=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use train_test_split from sklearn to split the data into 80% training and 20% testing sets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data[\"review_body\"], text_data[\"label\"], test_size=0.2, random_state=100)\n",
    "\n",
    "#We ignore terms that have a document frequency strictly higher 0.7 and document frequency strictly lower than 1.\n",
    "vectorizer = TfidfVectorizer(min_df=1, max_df=0.7)\n",
    "Xtrain = vectorizer.fit_transform(X_train)\n",
    "Xtest = vectorizer.transform(X_test)\n",
    "print(Xtrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we standardize the data using StandardScaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Create the instance\n",
    "sc = StandardScaler(with_mean=False)\n",
    "\n",
    "#We fit the scaler to the training feauture set only\n",
    "sc.fit(Xtrain)\n",
    "\n",
    "#Scale or Transform the training and the testing tests using the scaler that was fitted to training data\n",
    "Xtrain_std = sc.transform(Xtrain)\n",
    "Xtest_std = sc.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x-\n",
      "\n",
      "Testing Accuracy:0.8279\n",
      "Testing f1_Score:0.8274\n",
      "Testing Precision:0.8267\n",
      "Testing recall_score:0.8280\n",
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\n",
      "\n",
      "Training Accuracy:0.9262\n",
      "Training f1_Score:0.9263\n",
      "Training Precision:0.9266\n",
      "Training recall_score:0.9259\n"
     ]
    }
   ],
   "source": [
    "#implementation of perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Create a perceptron object with the parameters: 40 iterations (epochs) over the data, and a learning rate of 0.1\n",
    "ppn = Perceptron(max_iter=40, eta0=0.1, random_state=100)\n",
    "\n",
    "# Fit the model to the standardized data\n",
    "ppn.fit(Xtrain_std, y_train)\n",
    "\n",
    "\n",
    "# Apply the trained perceptron on the X data to make predicts for the Y test data\n",
    "y_pred_test = ppn.predict(Xtest_std)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_score,precision_score and recall_score\"\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x-\\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = ppn.predict(Xtrain_std)\n",
    "\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \n",
      "\n",
      "Testing Accuracy:0.8977\n",
      "Testing f1_Score:0.8970\n",
      "Testing Precision:0.8992\n",
      "Testing recall_score:0.8949\n",
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \n",
      "\n",
      "Training Accuracy:0.9335\n",
      "Training f1_Score:0.9334\n",
      "Training Precision:0.9353\n",
      "Training recall_score:0.9315\n"
     ]
    }
   ],
   "source": [
    "#implementation of SVM\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a Classifier for svm\n",
    "clf = svm.LinearSVC() # We are using Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(Xtrain, y_train)\n",
    "\n",
    "#Apply the trained svm on Xtrain_std data to make predictions for the test data\n",
    "y_pred_test = clf.predict(Xtest)\n",
    "\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = clf.predict(Xtrain)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_Score,Precision_score and recall_score\"\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-x--x- Accuracy, Precision, Recall, and f1-score on test data --x--x-\n",
      "\n",
      "Testing Accuracy:0.8982\n",
      "Testing f1_Score:0.8973\n",
      "Testing Precision:0.9021\n",
      "Testing recall_score:0.8925\n",
      "\n",
      "-x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\n",
      "\n",
      "Training Accuracy:0.9136\n",
      "Training f1_Score:0.9133\n",
      "Training Precision:0.9174\n",
      "Training recall_score:0.9092\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# instantiate the model \n",
    "logreg = LogisticRegression(max_iter = 5000)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(Xtrain,y_train)\n",
    "\n",
    "#Apply the trained Logistic Regression on Xtrain_std data to make predictions for the test data\n",
    "y_pred_test=logreg.predict(Xtest)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_Score,Precision_score and recall_score\"\n",
    "print(\"\\n-x--x- Accuracy, Precision, Recall, and f1-score on test data --x--x-\\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = logreg.predict(Xtrain)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score\"\n",
    "\n",
    "print(\"\\n-x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x-\\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \n",
      "\n",
      "Testing Accuracy:0.8695\n",
      "Testing f1_Score:0.8681\n",
      "Testing Precision:0.8740\n",
      "Testing recall_score:0.8622\n",
      "\n",
      " -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \n",
      "\n",
      "Training Accuracy:0.8866\n",
      "Training f1_Score:0.8864\n",
      "Training Precision:0.8891\n",
      "Training recall_score:0.8836\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(Xtrain, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_pred_test=model.predict(Xtest)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score,f1_Score,Precision_score and recall_score\"\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on test data -x--x- \\n\")\n",
    "\n",
    "print(f'Testing Accuracy:{accuracy_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing f1_Score:{f1_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing Precision:{precision_score(y_test, y_pred_test):.4f}')\n",
    "print(f'Testing recall_score:{recall_score(y_test, y_pred_test):.4f}')\n",
    "\n",
    "#Apply the trained perceptron on the data to make predicts for the trained data\n",
    "y_pred_tarin = model.predict(Xtrain)\n",
    "\n",
    "#We measure the performance using the \"accuracy_score\"\n",
    "\n",
    "print(\"\\n -x--x- Accuracy, Precision, Recall, and f1-score on train data -x--x- \\n\")\n",
    "\n",
    "print(f'Training Accuracy:{accuracy_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training f1_Score:{f1_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training Precision:{precision_score(y_train, y_pred_tarin):.4f}')\n",
    "print(f'Training recall_score:{recall_score(y_train, y_pred_tarin):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
