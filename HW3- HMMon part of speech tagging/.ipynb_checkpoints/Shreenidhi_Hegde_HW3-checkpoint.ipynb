{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e00a57",
   "metadata": {},
   "source": [
    "# HW3 Solution Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb647e",
   "metadata": {},
   "source": [
    "<b>Task 1 Vocabulary Creation<b>:\n",
    "    \n",
    "I iterate through each row in the training data and create the \"vocab\" dictionary which contains the word as a key and it's total number of occurances in the training data as value. Similarly, dictionary of all the tags and it's total number of occurances is stored in dictionary named \"pos_dict\".\n",
    "I have kept the threshold as 2 and replaces words which has less than the threshold  with the special token `< unk >' \n",
    "I created the vocabulary using the training data and did output the vocabulary into vocab.txt.\n",
    "\n",
    "<b> 1) What is the selected threshold for unknown words replacement?<b>\n",
    "    \n",
    "    ........ The selected threshold for unknown words replacement is 2 ........\n",
    "\n",
    "<b> 2) What is the total size of your vocabulary? <b>\n",
    "    \n",
    "    ........ Total size of vocabulary is 23183 ........\n",
    "\n",
    "<b> 3) What is the total size of your vocabulary and what is the total occurrences of the special token `< unk >' after replacement?<b>\n",
    "    \n",
    "    ........ The total occurrences of the special token ‘< unk >’ after replacement is 20011 ........\n",
    "    \n",
    "    \n",
    "<b> Task 2 Model Learning: <b>\n",
    "    \n",
    "Emission and transition parameters in HMM are in the following formulation:\n",
    "    \n",
    "<b>t(s′ |s) = count(s→s′ )/ count(s) <b>\n",
    "    \n",
    "<b>e(x|s) = count(s→x)/count(s)<b>\n",
    "    \n",
    "where t(·|·) is the transition parameter and e(·|·) is the emission parameter.\n",
    "I have calculated transmission and emission probabilities according to the above formula.\n",
    "After learning a model , I have output the learned model into a model file in json format, named hmm.json. The\n",
    "model file contains two dictionaries for the emission and transition parameters, respectively. The first dictionary, named transition, contains items with pairs of (s; s0) as key and t(s0js) as value. The second dictionary,\n",
    "named emission, contains items with pairs of (s; x) as key and e(xjs) as value.\n",
    "    \n",
    "<b> 1) How many transition and emission parameters in your HMM? <b>\n",
    "    \n",
    "    ........ The number of emission parameters is  30303 ........\n",
    "\n",
    "    ........ The number of transmission parameters is  1392 .......\n",
    "\n",
    "    \n",
    "<b> Task 3 Greedy Decoding withHMM: <b>\n",
    "    \n",
    "Greedy decoding: just go left-to-right and pick the highest probability choice each time.\n",
    "For\ti =\t1 to N: choose the tag\tthat maximizes the transition probability × emission probability.\n",
    "    \n",
    "<b> 1) What is the accuracy on dev data?<b>\n",
    "    \n",
    "    ........ Accuracy of dev data is 93.52718385439199 ........\n",
    "    \n",
    "<b> Task 4 Viterbi Decoding with HMM <b>\n",
    "    \n",
    "The Viterbi algorithm is a dynamic programming algorithm for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden states—called the Viterbi path—that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).\n",
    "    \n",
    "Intuition:\tthe\tbest path of length\ti ending in\tstate t must include the best path of length i−1 to\tthe\t previous state. So,\n",
    "– Find\tthe\tbest path of length\ti−1 to\teach state.\n",
    "– Consider\textending each\tof\tthose by 1 step, to\tstate t.\n",
    "– Take\tthe\tbest of\tthose options as the best path to state\tt.\n",
    "    \n",
    "    \n",
    "<b> 1) What is the accuracy on dev data? <b>\n",
    "    \n",
    "    ........ Accuracy of dev data is 94.8114245812176 ........\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95873b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb0c47",
   "metadata": {},
   "source": [
    "## Task 1 Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c17ef4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "pos_dict = {}\n",
    "sentences = 1\n",
    "alpha = 1\n",
    "with open('data/train', newline='') as tsvfile:\n",
    "    \n",
    "    text_data = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for row in text_data:      \n",
    "        try:             \n",
    "            if row[2].strip() not in pos_dict:\n",
    "                pos_dict[row[2].strip()] = 1\n",
    "            else:\n",
    "                pos_dict[row[2].strip()] +=1\n",
    "\n",
    "            if row[1].strip() not in vocab:\n",
    "                vocab[row[1].strip()] = 1\n",
    "            else:\n",
    "                vocab[row[1].strip()] +=1 \n",
    "            \n",
    "        except:\n",
    "            sentences += 1\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "894cfee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2\n",
    "unknowns = sum(val if val < threshold else 0 for key,val in vocab.items())\n",
    "vocab = {key:val for key, val in vocab.items() if val >= threshold}\n",
    "vocab = dict(sorted(vocab.items(), key=lambda x: x[1], reverse= True))\n",
    "vocab = {'<unk>':unknowns, **vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6303ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ The selected threshold for unknown words replacement is 2 ........\n",
      "\n",
      "........ Total size of vocabulary is 23183 ........\n",
      "\n",
      "........ The total occurrences of the special token ‘< unk >’ after replacement is 20011 ........\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"........ The selected threshold for unknown words replacement is 2 ........\\n\")\n",
    "print(\"........ Total size of vocabulary is \"+str(len(vocab))+\" ........\\n\")\n",
    "print(\"........ The total occurrences of the special token ‘< unk >’ after replacement is \"+str(unknowns)+\" ........\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b886f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing into vocab.txt file\n",
    "\n",
    "with open('vocab.txt', 'w') as f:\n",
    "    for idx, (word, count) in enumerate(vocab.items()):\n",
    "        f.write(str(word)+'\\t'+str(idx+1)+'\\t'+str(count)+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b560dcd8",
   "metadata": {},
   "source": [
    "## Task 2 Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed8ec8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = \"^\"\n",
    "pos_dict = {prev:sentences, **pos_dict}\n",
    "transmission_data = defaultdict(int)\n",
    "emission_data = defaultdict(int)\n",
    "with open('data/train', newline='') as tsvfile:\n",
    "    text_data = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for row in text_data:\n",
    "        try :\n",
    "            transmission_data[(prev,row[2])]+=1\n",
    "            if row[1] in vocab:\n",
    "                emission_data[(row[2], row[1])] += 1\n",
    "            else:\n",
    "                emission_data[(row[2],'<unk>')] += 1\n",
    "            prev = row[2]\n",
    "        except:\n",
    "            prev = \"^\"\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d55aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we find the transmission and emission probabilities\n",
    "\n",
    "transmission_prob = defaultdict()\n",
    "emission_prob = defaultdict()\n",
    "for key,value in transmission_data.items():\n",
    "    transmission_prob[key] = (value+alpha)/(pos_dict[key[0]]+alpha*(len(pos_dict)-1))\n",
    "\n",
    "for key,value in emission_data.items():\n",
    "    emission_prob[key] = value/pos_dict[key[0]]\n",
    "\n",
    "\n",
    "for p1 in pos_dict.keys():\n",
    "    for p2 in pos_dict.keys():\n",
    "        if p2 == '^':\n",
    "            continue\n",
    "        if (p1, p2) not in transmission_prob:\n",
    "            transmission_prob[(p1, p2)] = alpha/(pos_dict[p1]+alpha*(len(pos_dict)-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71f0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ The number of emission parameters is  30303 ........\n",
      "\n",
      "........ The number of transmission parameters is  1392 .......\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"........ The number of emission parameters is \",len(emission_data),\"........\\n\")\n",
    "print(\"........ The number of transmission parameters is \",len(transmission_data),\".......\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ed4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Output learned model into model file in json format - hmm.json\n",
    "\n",
    "import json\n",
    "    \n",
    "transmission_dict = dict((','.join(k), v) for k,v in transmission_prob.items())  \n",
    "emission_dict = dict((','.join(k), v) for k,v in emission_prob.items())\n",
    "   \n",
    "hmm = {'transmission': transmission_dict, 'emission': emission_dict}\n",
    "with open(\"hmm.json\", \"w\") as outfile:\n",
    "    json.dump(hmm, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9457d5",
   "metadata": {},
   "source": [
    "## Task 3 Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb6d417a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>words</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, Arizona, Corporations, Commission, autho...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, ruling, follows, a, host, of, problems, ...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, Arizona, regulatory, ruling, calls, for,...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, company, had, sought, increases, totalin...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The, decision, was, announced, after, trading...</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>5523</td>\n",
       "      <td>[But, if, the, board, rejects, a, reduced, bid...</td>\n",
       "      <td>[CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>5524</td>\n",
       "      <td>[The, pilots, could, play, hardball, by, notin...</td>\n",
       "      <td>[DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>5525</td>\n",
       "      <td>[If, they, were, to, insist, on, a, low, bid, ...</td>\n",
       "      <td>[IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>5526</td>\n",
       "      <td>[Also, ,, because, UAL, Chairman, Stephen, Wol...</td>\n",
       "      <td>[RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>5527</td>\n",
       "      <td>[That, could, cost, him, the, chance, to, infl...</td>\n",
       "      <td>[DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_number                                              words  \\\n",
       "0                   1  [The, Arizona, Corporations, Commission, autho...   \n",
       "1                   2  [The, ruling, follows, a, host, of, problems, ...   \n",
       "2                   3  [The, Arizona, regulatory, ruling, calls, for,...   \n",
       "3                   4  [The, company, had, sought, increases, totalin...   \n",
       "4                   5  [The, decision, was, announced, after, trading...   \n",
       "...               ...                                                ...   \n",
       "5522             5523  [But, if, the, board, rejects, a, reduced, bid...   \n",
       "5523             5524  [The, pilots, could, play, hardball, by, notin...   \n",
       "5524             5525  [If, they, were, to, insist, on, a, low, bid, ...   \n",
       "5525             5526  [Also, ,, because, UAL, Chairman, Stephen, Wol...   \n",
       "5526             5527  [That, could, cost, him, the, chance, to, infl...   \n",
       "\n",
       "                                               pos_tags  \n",
       "0     [DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...  \n",
       "1     [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...  \n",
       "2     [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...  \n",
       "3     [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...  \n",
       "4                    [DT, NN, VBD, VBN, IN, NN, VBD, .]  \n",
       "...                                                 ...  \n",
       "5522  [CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...  \n",
       "5523  [DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...  \n",
       "5524  [IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...  \n",
       "5525  [RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...  \n",
       "5526  [DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...  \n",
       "\n",
       "[5527 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev = []\n",
    "words = []\n",
    "pos_tags = []\n",
    "\n",
    "sent_count = 1\n",
    "with open('data/dev', newline = '') as tsvfile:\n",
    "    csv_reader = csv.reader(tsvfile, delimiter = '\\t')\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            words.append(row[1])\n",
    "            pos_tags.append(row[2])\n",
    "        except:\n",
    "            data_dev.append([sent_count, words, pos_tags])\n",
    "            sent_count += 1\n",
    "            words = []\n",
    "            pos_tags = []\n",
    "    data_dev.append([sent_count, words, pos_tags])\n",
    "df_dev = pd.DataFrame(data_dev,columns = ['sentence_number', 'words', 'pos_tags'])\n",
    "df_dev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a97b11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>words</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, Arizona, Corporations, Commission, autho...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, ruling, follows, a, host, of, problems, ...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, Arizona, regulatory, ruling, calls, for,...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, company, had, sought, increases, totalin...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The, decision, was, announced, after, trading...</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>5523</td>\n",
       "      <td>[But, if, the, board, rejects, a, reduced, bid...</td>\n",
       "      <td>[CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>5524</td>\n",
       "      <td>[The, pilots, could, play, hardball, by, notin...</td>\n",
       "      <td>[DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>5525</td>\n",
       "      <td>[If, they, were, to, insist, on, a, low, bid, ...</td>\n",
       "      <td>[IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>5526</td>\n",
       "      <td>[Also, ,, because, UAL, Chairman, Stephen, Wol...</td>\n",
       "      <td>[RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>5527</td>\n",
       "      <td>[That, could, cost, him, the, chance, to, infl...</td>\n",
       "      <td>[DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5527 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_number                                              words  \\\n",
       "0                   1  [The, Arizona, Corporations, Commission, autho...   \n",
       "1                   2  [The, ruling, follows, a, host, of, problems, ...   \n",
       "2                   3  [The, Arizona, regulatory, ruling, calls, for,...   \n",
       "3                   4  [The, company, had, sought, increases, totalin...   \n",
       "4                   5  [The, decision, was, announced, after, trading...   \n",
       "...               ...                                                ...   \n",
       "5522             5523  [But, if, the, board, rejects, a, reduced, bid...   \n",
       "5523             5524  [The, pilots, could, play, hardball, by, notin...   \n",
       "5524             5525  [If, they, were, to, insist, on, a, low, bid, ...   \n",
       "5525             5526  [Also, ,, because, UAL, Chairman, Stephen, Wol...   \n",
       "5526             5527  [That, could, cost, him, the, chance, to, infl...   \n",
       "\n",
       "                                               pos_tags  \n",
       "0     [DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...  \n",
       "1     [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...  \n",
       "2     [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...  \n",
       "3     [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...  \n",
       "4                    [DT, NN, VBD, VBN, IN, NN, VBD, .]  \n",
       "...                                                 ...  \n",
       "5522  [CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...  \n",
       "5523  [DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...  \n",
       "5524  [IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...  \n",
       "5525  [RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...  \n",
       "5526  [DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...  \n",
       "\n",
       "[5527 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8d7742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, ground_truth):\n",
    "    correct_matches = 0\n",
    "    total_words = 0\n",
    "    for pred, gt in zip(predictions, ground_truth):\n",
    "        correct_matches += np.sum(np.array(pred) == np.array(gt))\n",
    "        total_w\n",
    "        ords +=  len(pred)\n",
    "    accuracy = correct_matches/total_words\n",
    "    return accuracy*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99587736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def greedy_decoding(df):\n",
    "    predicted_tags_list = []\n",
    "    accuaracy_list = [] \n",
    "    \n",
    "    for idx, (_, words) in df.iterrows():\n",
    "        predicted_tags = []\n",
    "        prec_pos_tag = '^'\n",
    "        for word in words:\n",
    "            max_proba = 0\n",
    "            best_tag = random.choice(list(pos_dict.keys()))\n",
    "            for pos_tag in pos_dict.keys():\n",
    "                if word not in vocab:\n",
    "                    word = '<unk>'\n",
    "                    \n",
    "                if pos_tag == '^':\n",
    "                    continue\n",
    "                \n",
    "                if (pos_tag, word) in emission_prob:\n",
    "                    tp =  transmission_prob[(prec_pos_tag, pos_tag)] \n",
    "                    ep = emission_prob[(pos_tag, word)] \n",
    "                    proba = tp*ep\n",
    "                    if proba > max_proba:\n",
    "                        max_proba = proba\n",
    "                        best_tag = pos_tag\n",
    "\n",
    "                        \n",
    "            predicted_tags.append(best_tag)\n",
    "            prec_pos_tag = best_tag\n",
    "        \n",
    "#         correct_matches = np.sum(np.array(pos_tags) == np.array(predicted_tags))\n",
    "#         accuracy = correct_matches/len(pos_tags)\n",
    "#         accuaracy_list.append(accuracy)\n",
    "    \n",
    "        predicted_tags_list.append(predicted_tags)\n",
    "        \n",
    "    return predicted_tags_list\n",
    "\n",
    "df_dev_greedy = df_dev.copy()\n",
    "df_dev_greedy['predicted_tags'] = greedy_decoding(df_dev_greedy.loc[:,['sentence_number', 'words']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89c4d5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>words</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, Arizona, Corporations, Commission, autho...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "      <td>[DT, NNP, NNS, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, ruling, follows, a, host, of, problems, ...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, Arizona, regulatory, ruling, calls, for,...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, VBN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, company, had, sought, increases, totalin...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The, decision, was, announced, after, trading...</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>5523</td>\n",
       "      <td>[But, if, the, board, rejects, a, reduced, bid...</td>\n",
       "      <td>[CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...</td>\n",
       "      <td>[CC, IN, DT, NN, NN, DT, JJ, NN, CC, VBZ, TO, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>5524</td>\n",
       "      <td>[The, pilots, could, play, hardball, by, notin...</td>\n",
       "      <td>[DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...</td>\n",
       "      <td>[DT, NNS, MD, VB, JJ, IN, VBG, PRP, VBP, JJ, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>5525</td>\n",
       "      <td>[If, they, were, to, insist, on, a, low, bid, ...</td>\n",
       "      <td>[IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...</td>\n",
       "      <td>[IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>5526</td>\n",
       "      <td>[Also, ,, because, UAL, Chairman, Stephen, Wol...</td>\n",
       "      <td>[RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...</td>\n",
       "      <td>[RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5526</th>\n",
       "      <td>5527</td>\n",
       "      <td>[That, could, cost, him, the, chance, to, infl...</td>\n",
       "      <td>[DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...</td>\n",
       "      <td>[DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5527 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_number                                              words  \\\n",
       "0                   1  [The, Arizona, Corporations, Commission, autho...   \n",
       "1                   2  [The, ruling, follows, a, host, of, problems, ...   \n",
       "2                   3  [The, Arizona, regulatory, ruling, calls, for,...   \n",
       "3                   4  [The, company, had, sought, increases, totalin...   \n",
       "4                   5  [The, decision, was, announced, after, trading...   \n",
       "...               ...                                                ...   \n",
       "5522             5523  [But, if, the, board, rejects, a, reduced, bid...   \n",
       "5523             5524  [The, pilots, could, play, hardball, by, notin...   \n",
       "5524             5525  [If, they, were, to, insist, on, a, low, bid, ...   \n",
       "5525             5526  [Also, ,, because, UAL, Chairman, Stephen, Wol...   \n",
       "5526             5527  [That, could, cost, him, the, chance, to, infl...   \n",
       "\n",
       "                                               pos_tags  \\\n",
       "0     [DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...   \n",
       "1     [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...   \n",
       "2     [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...   \n",
       "3     [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...   \n",
       "4                    [DT, NN, VBD, VBN, IN, NN, VBD, .]   \n",
       "...                                                 ...   \n",
       "5522  [CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...   \n",
       "5523  [DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...   \n",
       "5524  [IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...   \n",
       "5525  [RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...   \n",
       "5526  [DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...   \n",
       "\n",
       "                                         predicted_tags  \n",
       "0     [DT, NNP, NNS, NNP, VBD, DT, CD, NN, NN, NN, I...  \n",
       "1     [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...  \n",
       "2     [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, VBN,...  \n",
       "3     [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...  \n",
       "4                    [DT, NN, VBD, VBN, IN, NN, VBD, .]  \n",
       "...                                                 ...  \n",
       "5522  [CC, IN, DT, NN, NN, DT, JJ, NN, CC, VBZ, TO, ...  \n",
       "5523  [DT, NNS, MD, VB, JJ, IN, VBG, PRP, VBP, JJ, T...  \n",
       "5524  [IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...  \n",
       "5525  [RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...  \n",
       "5526  [DT, MD, VB, PRP, DT, NN, TO, VB, DT, NN, CC, ...  \n",
       "\n",
       "[5527 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_greedy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "414ec672",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wg/9xbdgjcd5r3_qdm7vt018l980000gn/T/ipykernel_1405/3888996800.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dev_greedy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicted_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dev_greedy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wg/9xbdgjcd5r3_qdm7vt018l980000gn/T/ipykernel_1405/3357901350.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(predictions, ground_truth)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcorrect_matches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtotal_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mords\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_matches\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total_w' is not defined"
     ]
    }
   ],
   "source": [
    "acc = accuracy(df_dev_greedy['predicted_tags'].tolist(), df_dev_greedy['pos_tags'].tolist())\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3696d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ Accuracy of dev data is 93.52718385439199 ........\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"........ Accuracy of dev data is\",acc,\"........\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecc1ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = []\n",
    "words = []\n",
    "pos_tags = []\n",
    "\n",
    "sent_count = 1\n",
    "with open('data/test', newline = '') as tsvfile:\n",
    "    csv_reader = csv.reader(tsvfile, delimiter = '\\t')\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            words.append(row[1])\n",
    "        except:\n",
    "            data_test.append([sent_count, words])\n",
    "            sent_count += 1\n",
    "            words = []\n",
    "            pos_tags = []\n",
    "            \n",
    "df_test = pd.DataFrame(data_test,columns = ['sentence_number', 'words'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "532ce52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_greedy = df_test.copy()\n",
    "df_test_greedy['predicted_tags'] = greedy_decoding(df_test_greedy)\n",
    "with open('greedy.out', 'w') as tsvfile:\n",
    "    for _, (_, words, predicted_tags) in df_test_greedy.iterrows():\n",
    "        idx = 0\n",
    "        for word, pos_tag in zip(words, predicted_tags):\n",
    "            print (\"%d\\t%s\\t%s\" % (idx+1, word, pos_tag), file=tsvfile)\n",
    "            idx += 1\n",
    "        if idx != len(df_test_greedy.index):\n",
    "            print('\\n', file=tsvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6107e45",
   "metadata": {},
   "source": [
    "## Task 4  Viterbi Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7596925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(df):\n",
    "    \n",
    "    prec_pos_tag = '<POS>'\n",
    "    predicted_tags_list = []\n",
    "    accuaracy_list = [] \n",
    "    \n",
    "    for idx, (_, words) in df.iterrows():\n",
    "        predicted_tags = []\n",
    "        T = len(words)\n",
    "        N = len(pos_dict.items())\n",
    "        viterbi = [[0]*(T) for _ in range(N)]\n",
    "        backpointer = [[0]*(T) for _ in range(N)]\n",
    "        \n",
    "        for t, word in enumerate(words):\n",
    "            \n",
    "            if word not in vocab:\n",
    "                word = '<unk>'\n",
    "            for s, pos_tag in enumerate(pos_dict.keys()):\n",
    "                if s == 0:\n",
    "                    pass\n",
    "                elif t == 0:\n",
    "                    tp =  transmission_prob[('^', pos_tag)] \n",
    "                    ep = emission_prob[(pos_tag, word)] if (pos_tag, word) in emission_prob else 0\n",
    "        \n",
    "                    viterbi[s][0] = tp * ep\n",
    "                    backpointer[s][0] = 0\n",
    "                else:\n",
    "                    backpointer[s][t] = random.randint(1,len(pos_dict)-1)\n",
    "                    for s1, prec_pos in enumerate(pos_dict.keys()):\n",
    "                        if s1 == 0:\n",
    "                            continue\n",
    "\n",
    "                        if (pos_tag, word) in emission_prob:\n",
    "                            tp =  transmission_prob[(prec_pos, pos_tag)] \n",
    "                            ep = emission_prob[(pos_tag, word)] \n",
    "                            cur_proba = viterbi[s1][t-1]*tp*ep\n",
    "\n",
    "                            if cur_proba > viterbi[s][t]:\n",
    "                                viterbi[s][t] = cur_proba\n",
    "                                backpointer[s][t] = s1\n",
    "                            \n",
    "            \n",
    "        bestpathprob = -1\n",
    "        bestpathpointer = 0\n",
    "        for s in range(1, N):\n",
    "            if viterbi[s][T-1] >= bestpathprob:\n",
    "                bestpathprob = viterbi[s][T-1]\n",
    "                bestpathpointer = s\n",
    "        \n",
    "        bestpath = []\n",
    "        t = T-1\n",
    "        pos_list = list(pos_dict.keys())\n",
    "        while bestpathpointer != 0:\n",
    "            bestpath.append(pos_list[bestpathpointer])\n",
    "            bestpathpointer = backpointer[bestpathpointer][t]\n",
    "            t -= 1 \n",
    "\n",
    "        bestpath = bestpath[::-1]\n",
    "\n",
    "        predicted_tags_list.append(bestpath)\n",
    "        \n",
    "    return predicted_tags_list\n",
    "\n",
    "df_dev_viterbi = df_dev.copy(deep = True)\n",
    "df_dev_viterbi['predicted_tags'] = viterbi_decoding(df_dev_viterbi.loc[:,['sentence_number', 'words']])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d56069f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>words</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, Arizona, Corporations, Commission, autho...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "      <td>[DT, NNP, NNS, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, ruling, follows, a, host, of, problems, ...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, Arizona, regulatory, ruling, calls, for,...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, company, had, sought, increases, totalin...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The, decision, was, announced, after, trading...</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5521</th>\n",
       "      <td>5522</td>\n",
       "      <td>[The, pilot, union, is, vowing, to, pursue, an...</td>\n",
       "      <td>[DT, NN, NN, VBZ, VBG, TO, VB, DT, NN, WDT, DT...</td>\n",
       "      <td>[DT, NN, NN, VBZ, VBG, TO, VB, DT, NN, WDT, DT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5522</th>\n",
       "      <td>5523</td>\n",
       "      <td>[But, if, the, board, rejects, a, reduced, bid...</td>\n",
       "      <td>[CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...</td>\n",
       "      <td>[CC, IN, DT, NN, VBZ, DT, JJ, NN, CC, VBZ, TO,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5523</th>\n",
       "      <td>5524</td>\n",
       "      <td>[The, pilots, could, play, hardball, by, notin...</td>\n",
       "      <td>[DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...</td>\n",
       "      <td>[DT, NNS, MD, VB, VBN, IN, VBG, PRP, VBP, JJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5524</th>\n",
       "      <td>5525</td>\n",
       "      <td>[If, they, were, to, insist, on, a, low, bid, ...</td>\n",
       "      <td>[IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...</td>\n",
       "      <td>[IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5525</th>\n",
       "      <td>5526</td>\n",
       "      <td>[Also, ,, because, UAL, Chairman, Stephen, Wol...</td>\n",
       "      <td>[RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...</td>\n",
       "      <td>[RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5526 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_number                                              words  \\\n",
       "0                   1  [The, Arizona, Corporations, Commission, autho...   \n",
       "1                   2  [The, ruling, follows, a, host, of, problems, ...   \n",
       "2                   3  [The, Arizona, regulatory, ruling, calls, for,...   \n",
       "3                   4  [The, company, had, sought, increases, totalin...   \n",
       "4                   5  [The, decision, was, announced, after, trading...   \n",
       "...               ...                                                ...   \n",
       "5521             5522  [The, pilot, union, is, vowing, to, pursue, an...   \n",
       "5522             5523  [But, if, the, board, rejects, a, reduced, bid...   \n",
       "5523             5524  [The, pilots, could, play, hardball, by, notin...   \n",
       "5524             5525  [If, they, were, to, insist, on, a, low, bid, ...   \n",
       "5525             5526  [Also, ,, because, UAL, Chairman, Stephen, Wol...   \n",
       "\n",
       "                                               pos_tags  \\\n",
       "0     [DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...   \n",
       "1     [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...   \n",
       "2     [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...   \n",
       "3     [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...   \n",
       "4                    [DT, NN, VBD, VBN, IN, NN, VBD, .]   \n",
       "...                                                 ...   \n",
       "5521  [DT, NN, NN, VBZ, VBG, TO, VB, DT, NN, WDT, DT...   \n",
       "5522  [CC, IN, DT, NN, VBZ, DT, VBN, NN, CC, VBZ, TO...   \n",
       "5523  [DT, NNS, MD, VB, NN, IN, VBG, PRP, VBP, JJ, T...   \n",
       "5524  [IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...   \n",
       "5525  [RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...   \n",
       "\n",
       "                                         predicted_tags  \n",
       "0     [DT, NNP, NNS, NNP, VBD, DT, CD, NN, NN, NN, I...  \n",
       "1     [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...  \n",
       "2     [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...  \n",
       "3     [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...  \n",
       "4                    [DT, NN, VBD, VBN, IN, NN, VBD, .]  \n",
       "...                                                 ...  \n",
       "5521  [DT, NN, NN, VBZ, VBG, TO, VB, DT, NN, WDT, DT...  \n",
       "5522  [CC, IN, DT, NN, VBZ, DT, JJ, NN, CC, VBZ, TO,...  \n",
       "5523  [DT, NNS, MD, VB, VBN, IN, VBG, PRP, VBP, JJ, ...  \n",
       "5524  [IN, PRP, VBD, TO, VB, IN, DT, JJ, NN, IN, ,, ...  \n",
       "5525  [RB, ,, IN, NNP, NNP, NNP, NNP, CC, JJ, NNP, N...  \n",
       "\n",
       "[5526 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750e6bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.8114245812176"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = accuracy(df_dev_viterbi['predicted_tags'].tolist(), df_dev_viterbi['pos_tags'].tolist())\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09a3b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ Accuracy of dev data is 94.8114245812176 ........\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"........ Accuracy of dev data is\",acc,\"........\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_viterbi = df_test.copy()\n",
    "df_test_viterbi['predicted_tags'] = viterbi_decoding(df_test_viterbi)\n",
    "with open('viterbi.out', 'w') as tsvfile:\n",
    "    for _, (_, words, predicted_tags) in df_test_viterbi.iterrows():\n",
    "        idx = 0\n",
    "        for word, pos_tag in zip(words, predicted_tags):\n",
    "            print (\"%d\\t%s\\t%s\" % (idx+1, word, pos_tag), file=tsvfile)\n",
    "            idx += 1\n",
    "        if idx != len(df_test_viterbi.index):\n",
    "            print('\\n', file=tsvfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af4ee229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_dev</th>\n",
       "      <th>dev_vocab</th>\n",
       "      <th>predicted_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Influential, members, of, the, House, Ways, a...</td>\n",
       "      <td>[JJ, NNS, IN, DT, NNP, NNPS, CC, NNP, NNP, VBD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, bill, ,, whose, backers, include, Chairm...</td>\n",
       "      <td>[DT, NN, ,, WP$, NNS, VBP, NNP, NNP, NNP, -LRB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, bill, intends, to, restrict, the, RTC, t...</td>\n",
       "      <td>[DT, NN, VBZ, TO, VB, DT, NNP, TO, NNP, NNS, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[``, Such, agency, `, self-help, ', borrowing,...</td>\n",
       "      <td>[``, JJ, NN, ``, NNP, POS, NN, VBZ, JJ, CC, JJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[The, complex, financing, plan, in, the, S&amp;L, ...</td>\n",
       "      <td>[DT, JJ, NN, NN, IN, DT, NN, NN, NN, VBZ, VBG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456</th>\n",
       "      <td>5457</td>\n",
       "      <td>[The, men, also, will, be, faced, with, bridgi...</td>\n",
       "      <td>[DT, NNS, RB, MD, VB, VBN, IN, VBG, DT, NN, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>5458</td>\n",
       "      <td>[Says, Peter, Mokaba, ,, president, of, the, S...</td>\n",
       "      <td>[VBZ, NNP, NNP, ,, NN, IN, DT, NNP, NNP, NNP, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458</th>\n",
       "      <td>5459</td>\n",
       "      <td>[They, never, considered, themselves, to, be, ...</td>\n",
       "      <td>[PRP, RB, VBN, PRP, TO, VB, NN, RB, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>5460</td>\n",
       "      <td>[At, last, night, 's, rally, ,, they, called, ...</td>\n",
       "      <td>[IN, JJ, NN, POS, NN, ,, PRP, VBD, IN, PRP$, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>5461</td>\n",
       "      <td>[``, We, emphasize, discipline, because, we, k...</td>\n",
       "      <td>[``, PRP, VB, NN, IN, PRP, VBP, IN, DT, NN, VB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5461 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_dev                                          dev_vocab  \\\n",
       "0                1  [Influential, members, of, the, House, Ways, a...   \n",
       "1                2  [The, bill, ,, whose, backers, include, Chairm...   \n",
       "2                3  [The, bill, intends, to, restrict, the, RTC, t...   \n",
       "3                4  [``, Such, agency, `, self-help, ', borrowing,...   \n",
       "4                5  [The, complex, financing, plan, in, the, S&L, ...   \n",
       "...            ...                                                ...   \n",
       "5456          5457  [The, men, also, will, be, faced, with, bridgi...   \n",
       "5457          5458  [Says, Peter, Mokaba, ,, president, of, the, S...   \n",
       "5458          5459  [They, never, considered, themselves, to, be, ...   \n",
       "5459          5460  [At, last, night, 's, rally, ,, they, called, ...   \n",
       "5460          5461  [``, We, emphasize, discipline, because, we, k...   \n",
       "\n",
       "                                         predicted_tags  \n",
       "0     [JJ, NNS, IN, DT, NNP, NNPS, CC, NNP, NNP, VBD...  \n",
       "1     [DT, NN, ,, WP$, NNS, VBP, NNP, NNP, NNP, -LRB...  \n",
       "2     [DT, NN, VBZ, TO, VB, DT, NNP, TO, NNP, NNS, R...  \n",
       "3     [``, JJ, NN, ``, NNP, POS, NN, VBZ, JJ, CC, JJ...  \n",
       "4     [DT, JJ, NN, NN, IN, DT, NN, NN, NN, VBZ, VBG,...  \n",
       "...                                                 ...  \n",
       "5456  [DT, NNS, RB, MD, VB, VBN, IN, VBG, DT, NN, NN...  \n",
       "5457  [VBZ, NNP, NNP, ,, NN, IN, DT, NNP, NNP, NNP, ...  \n",
       "5458             [PRP, RB, VBN, PRP, TO, VB, NN, RB, .]  \n",
       "5459  [IN, JJ, NN, POS, NN, ,, PRP, VBD, IN, PRP$, N...  \n",
       "5460  [``, PRP, VB, NN, IN, PRP, VBP, IN, DT, NN, VB...  \n",
       "\n",
       "[5461 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bc449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
